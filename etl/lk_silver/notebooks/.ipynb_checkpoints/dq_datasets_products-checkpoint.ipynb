{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2c03d8-cd3a-4f21-85e5-c0868f64abab",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "  <img src=\"Resources/logo_unir.png\" alt=\"Logo UNIR\" height=\"150px\" width=\"25%\">\n",
    "</div>\n",
    "\n",
    "# **Universidad Internacional de La Rioja**\n",
    "## Escuela Superior de Ingeniería y Tecnología\n",
    "### Máster Universitario en Análisis y Visualización de Datos Masivos / Visual Analytics and Big Data\n",
    "\n",
    "### **Trabajo Final de Máster**\n",
    "#### Presentado por:\n",
    "- Cepeda Ramos, Jefferson\n",
    "- Mosquera Arce, Samek Fernando "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ef539-58d3-4c8b-b883-c51fe37d1238",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## **Objetivo del notebook: Proceso de calidad datasets Productos**\n",
    "\n",
    "Este proceso tiene como objetivo realizar un proceso de calidad y transformación de datasets de productos almacenados en la **capa Bronze** de un data lake en GCP (`gs://lk_bronze/GSC/products/`) para prepararlos y moverlos a la **capa Silver** (`gs://lk_silver/GSC/products/`). Los datos provienen de múltiples categorías (`software`, `musical_instruments`, `video_games`) y están en formato **Parquet**.\n",
    "\n",
    "El flujo general del proceso contempla los siguientes pasos:\n",
    "\n",
    "1.  **Unificación de Datos**:\n",
    "    * Leer los datasets de productos de las categorías `software`, `musical_instruments`, y `video_games` desde la capa Bronze.\n",
    "    * Unificar todos los DataFrames en un único DataFrame de Spark.\n",
    "    * Añadir una columna `category` a cada registro para identificar su origen (e.g., 'software', 'musical\\_instruments').\n",
    "\n",
    "2.  **Eliminación de Columna Vacía**:\n",
    "    * Eliminar la columna `bought_together`, ya que se ha identificado que está completamente vacía en todos los datasets.\n",
    "\n",
    "3.  **Manejo de Valores Duplicados**:\n",
    "    * Eliminar registros duplicados dentro del DataFrame unificado, considerando todas las columnas para una deduplicación completa.\n",
    "\n",
    "4.  **Manejo de Valores Nulos y Limpieza de Atributos Críticos**:\n",
    "    * **`price`**: Convertir el campo `price` a tipo `FloatType()`. Eliminar los registros donde el `price` sea nulo o no pueda ser casteado a un valor numérico válido, debido a su criticidad y la dificultad de una imputación precisa.\n",
    "    * **`main_category`**: Eliminar registros donde `main_category` sea nulo, ya que es un atributo fundamental para la clasificación del producto.\n",
    "    * **`store`**: Eliminar registros donde `store` sea nulo, por su importancia en la identificación de la procedencia del producto.\n",
    "    * **`rating_number` y `average_rating`**: Mantener los registros incluso si estos campos son nulos, ya que un producto sin calificaciones es un escenario válido y no requiere imputación para este nivel de calidad.\n",
    "\n",
    "5.  **Manejo de Campos Anidados (`images`, `videos`, `details`)**:\n",
    "    * Mantener la estructura anidada de los campos `images` (ArrayType de StructType), `videos` (ArrayType de StructType), y `details` (StructType) dentro del DataFrame principal. Esta práctica preserva la integridad del producto y es adecuada para la capa Silver, permitiendo mayor flexibilidad para explotar estos campos en capas posteriores (Gold) si es necesario.\n",
    "\n",
    "6.  **Almacenamiento en Capa Silver**:\n",
    "    * Los DataFrames resultantes del proceso de calidad se guardarán en la capa Silver, en formato **Parquet**.\n",
    "    * El almacenamiento se realizará por categoría, en las rutas `gs://lk_silver/GSC/products/ + [categoria]`, utilizando el modo `overwrite` para garantizar que los datos más recientes reemplacen a los anteriores.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca0bd9-d17b-43f4-92c3-4e72260b53d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instanciar SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42f3fe5-e916-4247-8ea8-f73b361429c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession inicializada.\n"
     ]
    }
   ],
   "source": [
    "# Inicializar SparkSession si no está ya disponible\n",
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession.builder.appName(\"AmazonReviewsProcessing\").getOrCreate()\n",
    "\n",
    "print(\"SparkSession inicializada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bacd2c6-1df6-4e71-9424-1586ad762cd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Insertar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e47ace-a644-4fa4-a6c3-c16a64c96d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    FloatType,\n",
    "    LongType,\n",
    "    ArrayType,\n",
    ")\n",
    "from pyspark.sql.functions import col, lit, when, regexp_replace, explode_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5323554-5407-494c-8650-6e5c4222fe3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definir Parámetros Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e09199-f782-4191-9718-84ffbb2cb0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema y rutas definidas.\n"
     ]
    }
   ],
   "source": [
    "# Definir el esquema explícito para los datasets de metadatos (productos)\n",
    "# Ajustes:\n",
    "# - 'price' a StringType() inicialmente para manejar valores no numéricos antes de castear.\n",
    "# - 'rating_number' a LongType() para mayor rango que IntType.\n",
    "# - Los campos de 'details' con nombres amigables para Spark (sin espacios ni caracteres especiales).\n",
    "product_schema = StructType([\n",
    "    StructField(\"main_category\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"average_rating\", FloatType(), True),\n",
    "    StructField(\"rating_number\", LongType(), True),\n",
    "    StructField(\"features\", ArrayType(StringType()), True),\n",
    "    StructField(\"description\", ArrayType(StringType()), True),\n",
    "    StructField(\"price\", StringType(), True),\n",
    "    StructField(\"images\", ArrayType(StructType([\n",
    "        StructField(\"thumb\", StringType(), True),\n",
    "        StructField(\"large\", StringType(), True),\n",
    "        StructField(\"hi_res\", StringType(), True),\n",
    "        StructField(\"variant\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"videos\", ArrayType(StructType([\n",
    "        StructField(\"title\", StringType(), True),\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"user_id\", StringType(), True)\n",
    "    ])), True),\n",
    "    StructField(\"store\", StringType(), True),\n",
    "    StructField(\"categories\", ArrayType(StringType()), True),\n",
    "    StructField(\"details\", StructType([\n",
    "        StructField(\"release_date\", StringType(), True),\n",
    "        StructField(\"date_first_listed_on_amazon\", StringType(), True),\n",
    "        StructField(\"developed_by\", StringType(), True),\n",
    "        StructField(\"size\", StringType(), True),\n",
    "        StructField(\"version\", StringType(), True),\n",
    "        StructField(\"application_permissions\", ArrayType(StringType()), True),\n",
    "        StructField(\"minimum_operating_system\", StringType(), True),\n",
    "        StructField(\"approximate_download_time\", StringType(), True)\n",
    "    ]), True),\n",
    "    StructField(\"parent_asin\", StringType(), True),\n",
    "    StructField(\"bought_together\", ArrayType(StringType()), True),\n",
    "    StructField(\"category\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Rutas de los datasets en GCP\n",
    "bronze_paths = {\n",
    "    \"software\": \"gs://lk_bronze/GSC/products/software\",\n",
    "    \"musical_instruments\": \"gs://lk_bronze/GSC/products/musical_instruments\",\n",
    "    \"video_games\": \"gs://lk_bronze/GSC/products/video_games\",\n",
    "}\n",
    "\n",
    "# Ruta de destino en la capa Silver\n",
    "silver_path = \"gs://lk_silver/GSC/products/\"\n",
    "\n",
    "print(\"Esquema y rutas definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdf686-e095-4fcf-8c6a-67f6d5a395b0",
   "metadata": {},
   "source": [
    "## Leer los dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0244822-f644-4beb-9a53-39072cc9c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo datos de: gs://lk_bronze/GSC/products/software con categoría: software\n",
      "Leyendo datos de: gs://lk_bronze/GSC/products/musical_instruments con categoría: musical_instruments\n",
      "Leyendo datos de: gs://lk_bronze/GSC/products/video_games con categoría: video_games\n",
      "Unificando DataFrames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros unificados antes de la calidad: 440113\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar los DataFrames individuales\n",
    "dfs = []\n",
    "\n",
    "# Leer cada dataset parquet desde \"gs://lk_bronze/GSC/\"\n",
    "for category, path in bronze_paths.items():\n",
    "    print(f\"Leyendo datos de: {path} con categoría: {category}\")\n",
    "    df = spark.read.schema(product_schema).parquet(path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Unificar todos los DataFrames\n",
    "print(\"Unificando DataFrames...\")\n",
    "df_products = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    df_products = df_products.unionByName(dfs[i], allowMissingColumns=True)\n",
    "\n",
    "print(f\"Total de registros unificados antes de la calidad: {df_products.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ba5cb-7c16-469b-9f89-35d992ac6362",
   "metadata": {},
   "source": [
    "## **Proceso de calidad de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d09a18e-380b-4325-83ec-878984f09869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando proceso de calidad de datos...\n",
      "Eliminando columna 'bought_together' (100% vacía).\n",
      "Eliminando valores duplicados considerando todos los atributos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros eliminados por duplicidad: 0\n",
      "Procesando la columna 'price'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros eliminados por precio nulo o inválido: 222278\n",
      "Procesando la columna 'main_category'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros eliminados por 'main_category' nula: 5345\n",
      "Procesando la columna 'store'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros eliminados por 'store' nula: 919\n",
      "Columnas 'rating_number' y 'average_rating': Se mantienen los valores nulos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros después del proceso de calidad: 211571\n",
      "root\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- average_rating: float (nullable = true)\n",
      " |-- rating_number: long (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- thumb: string (nullable = true)\n",
      " |    |    |-- large: string (nullable = true)\n",
      " |    |    |-- hi_res: string (nullable = true)\n",
      " |    |    |-- variant: string (nullable = true)\n",
      " |-- videos: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_id: string (nullable = true)\n",
      " |-- store: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- details: struct (nullable = true)\n",
      " |    |-- release_date: string (nullable = true)\n",
      " |    |-- date_first_listed_on_amazon: string (nullable = true)\n",
      " |    |-- developed_by: string (nullable = true)\n",
      " |    |-- size: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |    |-- application_permissions: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- minimum_operating_system: string (nullable = true)\n",
      " |    |-- approximate_download_time: string (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando proceso de calidad de datos...\")\n",
    "\n",
    "# Eliminar la columna 'bought_together'\n",
    "if \"bought_together\" in df_products.columns:\n",
    "    print(\"Eliminando columna 'bought_together' (100% vacía).\")\n",
    "    df_products = df_products.drop(\"bought_together\")\n",
    "else:\n",
    "    print(\"La columna 'bought_together' no existe o ya fue eliminada.\")\n",
    "\n",
    "# Eliminar valores duplicados\n",
    "print(\"Eliminando valores duplicados considerando todos los atributos.\")\n",
    "initial_count = df_products.count()\n",
    "df_products = df_products.dropDuplicates()\n",
    "deduplicated_count = df_products.count()\n",
    "print(f\"Registros eliminados por duplicidad: {initial_count - deduplicated_count}\")\n",
    "\n",
    "# Manejo de atributos con valores NULL\n",
    "# Castear 'price' a FloatType y manejar nulos\n",
    "print(\"Procesando la columna 'price'...\")\n",
    "# Limpiar el campo price para asegurar que solo contenga valores numéricos válidos\n",
    "# Se remueven comas si existen y se intenta convertir a float\n",
    "df_products = df_products.withColumn(\n",
    "    \"price_cleaned\",\n",
    "    regexp_replace(col(\"price\"), \",\", \"\").cast(FloatType())\n",
    ")\n",
    "\n",
    "# Eliminar registros donde 'price_cleaned' es NULL después del casteo\n",
    "# Esto manejará tanto los NULL originales como los valores que no pudieron ser casteados.\n",
    "price_null_count = df_products.filter(col(\"price_cleaned\").isNull()).count()\n",
    "df_products = df_products.filter(col(\"price_cleaned\").isNotNull())\n",
    "print(f\"Registros eliminados por precio nulo o inválido: {price_null_count}\")\n",
    "\n",
    "# Reemplazar la columna 'price' original con 'price_cleaned' y renombrarla\n",
    "df_products = df_products.withColumn(\"price\", col(\"price_cleaned\")).drop(\"price_cleaned\")\n",
    "\n",
    "# Eliminar registros donde 'main_category' es NULL\n",
    "print(\"Procesando la columna 'main_category'...\")\n",
    "main_category_null_count = df_products.filter(col(\"main_category\").isNull()).count()\n",
    "df_products = df_products.filter(col(\"main_category\").isNotNull())\n",
    "print(\n",
    "    f\"Registros eliminados por 'main_category' nula: {main_category_null_count}\"\n",
    ")\n",
    "\n",
    "# Eliminar registros donde 'store' es NULL\n",
    "print(\"Procesando la columna 'store'...\")\n",
    "store_null_count = df_products.filter(col(\"store\").isNull()).count()\n",
    "df_products = df_products.filter(col(\"store\").isNotNull())\n",
    "print(f\"Registros eliminados por 'store' nula: {store_null_count}\")\n",
    "\n",
    "# Mantener registros con 'rating_number' y 'average_rating' nulos. No se hace nada aquí.\n",
    "print(\n",
    "    \"Columnas 'rating_number' y 'average_rating': Se mantienen los valores nulos.\"\n",
    ")\n",
    "\n",
    "# Re-contar el total de registros después de las operaciones de calidad\n",
    "final_count = df_products.count()\n",
    "print(f\"Total de registros después del proceso de calidad: {final_count}\")\n",
    "\n",
    "# Verificar el esquema final\n",
    "df_products.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ec2b6-68df-4f69-a732-f86b6ef541db",
   "metadata": {},
   "source": [
    "## Almacenar datos limpios en capa Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0485ff29-f0fb-4939-85f4-d21ea75165a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando DataFrames procesados en la capa Silver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso de calidad y almacenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# Almacenamiento del dataset unificado en la capa Silver \"gs://lk_silver/GSC/products/\"\n",
    "print(\"Guardando DataFrames procesados en la capa Silver...\")\n",
    "\n",
    "df_products.write.mode(\"overwrite\").parquet(silver_path)\n",
    "\n",
    "print(\"Proceso de calidad y almacenamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f81d7-7d44-4846-9601-331f4e4f2c8c",
   "metadata": {},
   "source": [
    "## Detener SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97e3443-bb49-4897-b865-ca112c7f6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detener la SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
